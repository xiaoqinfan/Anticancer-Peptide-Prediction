import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from Bio import SeqIO
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
# è¡¥å……å¼•ç”¨ roc_curve å’Œ auc ç”¨äºç”»å›¾
from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report, roc_curve, auc
from xgboost import XGBClassifier
from sklearn.feature_selection import SelectFromModel
from sklearn.ensemble import VotingClassifier
from sklearn.preprocessing import StandardScaler

pos_file = "../positive.fasta"
neg_file = "../negative.fasta"
amino_acids = 'ACDEFGHIKLMNPQRSTVWY'

def get_aac_feature(seq):
    clean_seq = [aa for aa in seq if aa in amino_acids]
    length = len(clean_seq)
    if length == 0: return [0] * 20
    count_dict = {aa: 0 for aa in amino_acids}
    for aa in clean_seq: count_dict[aa] += 1
    return [count_dict[aa] / length for aa in amino_acids]

def get_cksaap_feature(seq, gap=0):
    aa_pairs = [aa1 + aa2 for aa1 in amino_acids for aa2 in amino_acids]
    pair_dict = {pair: i for i, pair in enumerate(aa_pairs)}
    feature = [0] * 400
    length = len(seq)
    if length <= gap + 1: return feature
    total_pairs = 0
    for i in range(length - gap - 1):
        pair = seq[i] + seq[i + gap + 1]
        if pair in pair_dict:
            feature[pair_dict[pair]] += 1
            total_pairs += 1
    if total_pairs > 0:
        feature = [count / total_pairs for count in feature]
    return feature


def get_physio_feature(seq):
    # ç–æ°´æ€§å€¼ (Hydrophobicity Index)
    hydrophobicity_map = {
        'A': 1.8, 'C': 2.5, 'D': -3.5, 'E': -3.5, 'F': 2.8,
        'G': -0.4, 'H': -3.2, 'I': 4.5, 'K': -3.9, 'L': 3.8,
        'M': 1.9, 'N': -3.5, 'P': -1.6, 'Q': -3.5, 'R': -4.5,
        'S': -0.8, 'T': -0.7, 'V': 4.2, 'W': -0.9, 'Y': -1.3
    }
    # ç”µè·å€¼ (Charge)
    charge_map = {
        'K': 1, 'R': 1, 'H': 0.1,  # æ­£ç”µè·
        'D': -1, 'E': -1,  # è´Ÿç”µè·
    }
    total_hydro = 0
    total_charge = 0
    valid_len = 0
    for aa in seq:
        if aa in amino_acids:
            total_hydro += hydrophobicity_map.get(aa, 0)
            total_charge += charge_map.get(aa, 0)
            valid_len += 1
    if valid_len == 0:
        return [0, 0]
    return [total_hydro / valid_len, total_charge / valid_len]


print("æ­£åœ¨è¯»å– FASTA æ–‡ä»¶...")
X = []
y = []

def process_file(filename, label):
    count = 0
    for record in SeqIO.parse(filename, "fasta"):
        seq_str = str(record.seq).upper()
        # ç‰¹å¾æå–
        feat_aac = get_aac_feature(seq_str)  # 20ç»´
        feat_k0 = get_cksaap_feature(seq_str, gap=0)  # 400ç»´
        feat_k1 = get_cksaap_feature(seq_str, gap=1)  # 400ç»´
        feat_phy = get_physio_feature(seq_str)  # 2ç»´

        # ç‰¹å¾èåˆ
        final_feat = list(feat_aac) + list(feat_k0) + list(feat_k1) + list(feat_phy)

        X.append(final_feat)
        y.append(label)
        count += 1
    return count

c1 = process_file(pos_file, 1)
c0 = process_file(neg_file, 0)
print(f"è¯»å–å®Œæ¯•: æ­£æ ·æœ¬ {c1} æ¡, è´Ÿæ ·æœ¬ {c0} æ¡")

X = np.array(X)
y = np.array(y)
print(f"åŸå§‹æ•°æ®ç»´åº¦: {X.shape}")


print("\nâš–ï¸ æ­£åœ¨è¿›è¡Œæ•°æ®æ ‡å‡†åŒ– (StandardScaler)...")
scaler = StandardScaler()
X = scaler.fit_transform(X)
print(f"æ ‡å‡†åŒ–å®Œæˆï¼å‡å€¼: {np.mean(X):.2f}, æ–¹å·®: {np.std(X):.2f}")


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)


print("\nğŸ” æ­£åœ¨è¿›è¡Œç‰¹å¾ç­›é€‰...")

# ç”ŸæˆåŸå§‹ç‰¹å¾åå­—
orig_feat_names = list(amino_acids)
aa_pairs = [aa1 + aa2 for aa1 in amino_acids for aa2 in amino_acids]
orig_feat_names += [f"{pair}_gap0" for pair in aa_pairs]
orig_feat_names += [f"{pair}_gap1" for pair in aa_pairs]
orig_feat_names += ["Avg_Hydrophobicity", "Avg_Charge"]

print(f"é¢„æœŸç‰¹å¾æ€»æ•°: {len(orig_feat_names)} (åº”ä¸º 822)")

# ç²—ç­›
selector_model = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42, n_jobs=-1)
selector_model.fit(X_train, y_train)

selection = SelectFromModel(selector_model, threshold="1.2*mean", prefit=True)
select_X_train = selection.transform(X_train)
select_X_test = selection.transform(X_test)

# è·å–è¢«é€‰ä¸­çš„ç‰¹å¾åå­—
selected_indices = selection.get_support(indices=True)
selected_feat_names = [orig_feat_names[i] for i in selected_indices]

print(f"âœ… ç­›é€‰å®Œæˆï¼ç»´åº¦å˜åŒ–: {X_train.shape[1]} -> {select_X_train.shape[1]}")


print("\nğŸ¤ æ­£åœ¨ç»„å»ºæ¨¡å‹è”ç›Ÿ (RandomForest + XGBoost)...")

rf_model = RandomForestClassifier(n_estimators=500, random_state=42, n_jobs=-1)

xgb_best = XGBClassifier(
    n_estimators=500, learning_rate=0.05, max_depth=3,
    subsample=0.8, colsample_bytree=0.8,
    random_state=42, n_jobs=-1, eval_metric='logloss'
)

ensemble_model = VotingClassifier(
    estimators=[('rf', rf_model), ('xgb', xgb_best)],
    voting='soft',
    n_jobs=-1
)

ensemble_model.fit(select_X_train, y_train)

preds = ensemble_model.predict(select_X_test)
probs = ensemble_model.predict_proba(select_X_test)[:, 1]

acc = accuracy_score(y_test, preds)
auc_score = roc_auc_score(y_test, probs)

print("-" * 30)
print(f"ğŸš€ [èåˆæ¨¡å‹] æœ€ç»ˆæµ‹è¯•é›†å‡†ç¡®ç‡: {acc:.4f}")
print(f"ğŸ”¥ [èåˆæ¨¡å‹] æœ€ç»ˆæµ‹è¯•é›† AUC   : {auc_score:.4f}")
print("-" * 30)

print("\nè¯¦ç»†åˆ†ç±»æŠ¥å‘Š:")
print(classification_report(y_test, preds))


cm = confusion_matrix(y_test, preds)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix (Ensemble)')
plt.show()


print("\nğŸ” æ­£åœ¨åˆ†æèåˆæ¨¡å‹çš„ç‰¹å¾é‡è¦æ€§...")

rf_fitted = ensemble_model.estimators_[0]
xgb_fitted = ensemble_model.estimators_[1]

rf_imp = rf_fitted.feature_importances_
xgb_imp = xgb_fitted.feature_importances_
avg_imp = (rf_imp + xgb_imp) / 2

indices = np.argsort(avg_imp)[::-1]

print("-" * 30)
print("ğŸ”¥ [èåˆæ¨¡å‹] è®¤ä¸ºæœ€é‡è¦çš„ Top 15 ç‰¹å¾:")
print("-" * 30)

for f in range(min(15, len(indices))):
    idx = indices[f]
    score = avg_imp[idx]
    name = selected_feat_names[idx]
    print(f"{f + 1:2d}. {name:<20} (æƒé‡: {score:.4f})")


print("\nğŸ§ª ç‰©ç†åŒ–å­¦ç‰¹å¾ (Physicochemical) è¡¨ç°å¦‚ä½•ï¼Ÿ")
phy_features = ["Avg_Hydrophobicity", "Avg_Charge"]

for phy_name in phy_features:
    if phy_name in selected_feat_names:
        real_idx = selected_feat_names.index(phy_name)
        real_score = avg_imp[real_idx]
        rank = np.where(indices == real_idx)[0][0] + 1
        print(f"  -> {phy_name}: æ’åç¬¬ {rank} / {len(selected_feat_names)}, æƒé‡: {real_score:.4f}")
    else:
        print(f"  -> {phy_name}: âŒ åœ¨ç‰¹å¾ç­›é€‰é˜¶æ®µè¢«å‰”é™¤äº†")


print("\nğŸ¨ æ­£åœ¨ç»˜åˆ¶æœ€ç»ˆçš„ ROC å¯¹æ¯”å›¾ (Figure 3)...")

# å•ç‹¬è®­ç»ƒ RF å’Œ XGB ä»¥ä¾¿ç”»å¯¹æ¯”çº¿
rf_model.fit(select_X_train, y_train)
y_prob_rf = rf_model.predict_proba(select_X_test)[:, 1]
fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf)
roc_auc_rf = auc(fpr_rf, tpr_rf)

xgb_best.fit(select_X_train, y_train)
y_prob_xgb = xgb_best.predict_proba(select_X_test)[:, 1]
fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_prob_xgb)
roc_auc_xgb = auc(fpr_xgb, tpr_xgb)

# èåˆæ¨¡å‹ (å·²ç»è®­ç»ƒè¿‡ï¼Œç›´æ¥é¢„æµ‹)
y_prob_ens = ensemble_model.predict_proba(select_X_test)[:, 1]
fpr_ens, tpr_ens, _ = roc_curve(y_test, y_prob_ens)
roc_auc_ens = auc(fpr_ens, tpr_ens)

plt.figure(figsize=(8, 6), dpi=150)
plt.plot(fpr_rf, tpr_rf, color='green', lw=2, alpha=0.6, label=f'Random Forest (AUC = {roc_auc_rf:.3f})')
plt.plot(fpr_xgb, tpr_xgb, color='blue', lw=2, alpha=0.6, label=f'XGBoost (AUC = {roc_auc_xgb:.3f})')
plt.plot(fpr_ens, tpr_ens, color='red', lw=3, label=f'Proposed Ensemble (AUC = {roc_auc_ens:.3f})')
plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate', fontsize=12)
plt.ylabel('True Positive Rate', fontsize=12)
plt.title('ROC Curves Comparison', fontsize=14)
plt.legend(loc="lower right", fontsize=11)
plt.grid(alpha=0.3)
plt.show()


print("\nğŸ“Š æ­£åœ¨ç”Ÿæˆ Figure 2 (æ··æ·†çŸ©é˜µå¯¹æ¯”å›¾)...")


# å®šä¹‰ä¸€ä¸ªç”»å›¾å‡½æ•°ï¼Œæ–¹ä¾¿é‡å¤ä½¿ç”¨
def plot_cm(model, X_test, y_test, title, filename):
    preds = model.predict(X_test)
    cm = confusion_matrix(y_test, preds)

    plt.figure(figsize=(5, 4), dpi=150)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
    plt.title(title, fontsize=12)
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.tight_layout()
    plt.savefig(filename)
    plt.show()
    print(f"âœ… å·²ä¿å­˜: {filename}")


# 1. ç»˜åˆ¶ (a) Random Forest
plot_cm(rf_model, select_X_test, y_test,
        '(a) Random Forest', '../Figure2_a_RandomForest_CM.png')

# 2. ç»˜åˆ¶ (b) XGBoost
plot_cm(xgb_best, select_X_test, y_test,
        '(b) XGBoost', '../Figure2_b_XGBoost_CM.png')

# 3. ç»˜åˆ¶ (c) Ensemble (Proposed)
plot_cm(ensemble_model, select_X_test, y_test,
        '(c) Ensemble Model', '../Figure2_c_Ensemble_CM.png')

